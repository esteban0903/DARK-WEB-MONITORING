import os
import requests
from bs4 import BeautifulSoup
import google.generativeai as genai
from dotenv import load_dotenv

# Cargar variables de entorno desde .env
load_dotenv()

# Configurar la API de Gemini
# Intentar obtener de secrets de Streamlit primero, luego de .env
try:
    import streamlit as st
    GEMINI_API_KEY = st.secrets.get("GEMINI_API_KEY", os.getenv("GEMINI_API_KEY"))
except:
    GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

if not GEMINI_API_KEY:
    raise ValueError("‚ö†Ô∏è GEMINI_API_KEY no encontrada. Configura el archivo .env o Streamlit secrets")
genai.configure(api_key=GEMINI_API_KEY)

def extraer_contenido_web(url: str, timeout: int = 10) -> str:
    """
    Extrae el contenido de texto de una URL usando BeautifulSoup con m√∫ltiples intentos.
    """
    # Lista de user agents a probar
    user_agents = [
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Safari/605.1.15',
        'Mozilla/5.0 (X11; Linux x86_64; rv:122.0) Gecko/20100101 Firefox/122.0',
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:122.0) Gecko/20100101 Firefox/122.0',
    ]
    
    for i, ua in enumerate(user_agents):
        try:
            headers = {
                'User-Agent': ua,
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
                'Accept-Language': 'en-US,en;q=0.9,es;q=0.8',
                'Accept-Encoding': 'gzip, deflate, br',
                'DNT': '1',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1',
                'Sec-Fetch-Dest': 'document',
                'Sec-Fetch-Mode': 'navigate',
                'Sec-Fetch-Site': 'none',
                'Sec-Fetch-User': '?1',
                'Cache-Control': 'max-age=0',
                'Referer': 'https://www.google.com/'
            }
            
            response = requests.get(
                url, 
                headers=headers, 
                timeout=timeout, 
                allow_redirects=True,
                verify=True
            )
            
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # Eliminar scripts, estilos, y elementos no √∫tiles
            for element in soup(["script", "style", "nav", "footer", "header", "aside", "iframe"]):
                element.decompose()
            
            # Intentar extraer el contenido principal
            contenido_principal = None
            
            # Buscar en selectores comunes de art√≠culos
            for selector in ['article', 'main', '.article-content', '.post-content', '.entry-content']:
                contenido = soup.select_one(selector)
                if contenido:
                    contenido_principal = contenido
                    break
            
            # Si no encontramos contenido principal, usar body
            if not contenido_principal:
                contenido_principal = soup.find('body')
            
            if contenido_principal:
                texto = contenido_principal.get_text(separator=' ', strip=True)
            else:
                texto = soup.get_text(separator=' ', strip=True)
            
            # Limpiar texto: remover espacios m√∫ltiples
            texto = ' '.join(texto.split())
            
            # Limitar a 12000 caracteres para m√°s contexto
            if len(texto) > 100:  # Si tiene contenido √∫til
                return texto[:12000]
            else:
                # Contenido muy corto, probar siguiente user agent
                if i < len(user_agents) - 1:
                    continue
                    
        except requests.exceptions.HTTPError as e:
            if e.response.status_code == 403 and i < len(user_agents) - 1:
                # Intentar con siguiente user agent
                continue
            elif e.response.status_code == 403:
                return "‚ö†Ô∏è ACCESO_BLOQUEADO"
            else:
                return f"‚ö†Ô∏è ERROR_HTTP_{e.response.status_code}"
                
        except requests.exceptions.Timeout:
            if i < len(user_agents) - 1:
                continue
            return "‚ö†Ô∏è TIMEOUT"
            
        except Exception as e:
            if i < len(user_agents) - 1:
                continue
            return f"‚ö†Ô∏è ERROR: {str(e)[:100]}"
    
    return "‚ö†Ô∏è NO_CONTENIDO"


def analizar_con_gemini(url: str, contenido: str) -> dict:
    """
    Analiza el contenido de una noticia usando Gemini y extrae informaci√≥n estructurada.
    """
    try:
        # Usar Gemini 2.5 Flash con configuraci√≥n de timeout
        model = genai.GenerativeModel(
            'gemini-2.5-flash',
            generation_config={
                'temperature': 0.3,
                'max_output_tokens': 2048,  # Limitar salida para respuestas m√°s r√°pidas
            }
        )
        
        prompt = f"""Eres un analista experto en ciberseguridad especializado en ransomware y ataques APT.

Analiza el siguiente contenido y extrae SOLO la informaci√≥n que est√© EXPL√çCITAMENTE mencionada. Si un dato NO aparece en el texto, escribe "No especificado".

URL: {url}

CONTENIDO:
{contenido}

---

Proporciona el an√°lisis en este formato EXACTO:

## üì∞ INFORMACI√ìN DE LA FUENTE
**Autor/Medio:** [nombre del medio]
**Fecha:** [fecha de publicaci√≥n]

## üé≠ ACTOR DE AMENAZA
**Nombre:** [grupo ransomware identificado: LockBit, BlackCat, RansomHub, etc.]
**Nivel de sofisticaci√≥n:** [Bajo/Medio/Alto/Muy Alto]

## üéØ V√çCTIMA
**Organizaci√≥n:** [nombre de la empresa/entidad afectada]
**Sector:** [industria: salud, finanzas, tecnolog√≠a, gobierno, etc.]
**Pa√≠s:** [ubicaci√≥n]
**Tama√±o:** [Peque√±a/Mediana/Grande empresa]

## üî¥ CRITICIDAD
**Nivel:** [üî¥ CR√çTICO / üü† ALTO / üü° MEDIO / üü¢ BAJO]
**Justificaci√≥n:** [1-2 l√≠neas explicando por qu√©]

**Impacto:**
- Datos comprometidos: [tipo y cantidad si se menciona]
- Sistemas afectados: [descripci√≥n breve]
- Rescate demandado: [monto si se conoce]

## üõ†Ô∏è MODUS OPERANDI
**Vector inicial:** [phishing/vulnerabilidad/RDP/VPN/otro]

**T√©cnicas MITRE ATT&CK detectadas:**
- Initial Access: [t√©cnica]
- Execution: [t√©cnica]
- Persistence: [t√©cnica]
- Lateral Movement: [t√©cnica]
- Exfiltration: [t√©cnica]
- Impact: [t√©cnica]

**Descripci√≥n del ataque:** [2-3 l√≠neas describiendo la secuencia del ataque]

## üîç INDICADORES DE COMPROMISO (IoCs)
**IPs sospechosas:** [lista o "No especificado"]
**Dominios maliciosos:** [lista o "No especificado"]
**Hashes de malware:** [MD5/SHA-256 o "No especificado"]
**Archivos maliciosos:** [nombres o "No especificado"]
**Otros IoCs:** [puertos/procesos/registry keys o "No especificado"]

## üõ°Ô∏è MITIGACI√ìN
**Acciones inmediatas:**
1. [acci√≥n prioritaria]
2. [acci√≥n recomendada]
3. [acci√≥n preventiva]

**Parches necesarios:** [CVE espec√≠fico o "No especificado"]

**Controles recomendados:**
- Detecci√≥n: [reglas SIEM/IDS]
- Prevenci√≥n: [configuraciones firewall/segmentaci√≥n]
- Respuesta: [procedimiento de IR]

## üìä RESUMEN EJECUTIVO
[2-3 l√≠neas: qu√© pas√≥, qui√©n fue afectado, gravedad, acci√≥n requerida]

## ‚ö†Ô∏è CONFIABILIDAD
**Nivel:** [Alta/Media/Baja]
**Raz√≥n:** [justificaci√≥n breve]

IMPORTANTE: S√© CONCISO y PRECISO. Extrae SOLO informaci√≥n presente en el texto. No inventes datos."""
        
        response = model.generate_content(prompt)

        # Extraer texto de la respuesta de forma defensiva: la SDK puede
        # devolver diferentes estructuras (text, candidates, message, etc.).
        analisis_text = None
        try:
            # Intento directo (accesor r√°pido)
            analisis_text = getattr(response, "text", None)

            # Revisar candidatos si no hay .text
            if not analisis_text:
                candidates = getattr(response, "candidates", None)
                if candidates:
                    cand = candidates[0]
                    analisis_text = getattr(cand, "text", None) or getattr(cand, "content", None) or getattr(cand, "output", None) or None

            # Revisar message / content
            if not analisis_text and hasattr(response, "message"):
                msg = getattr(response, "message")
                # Puede ser dict con 'content' como lista de partes
                if isinstance(msg, dict):
                    content = msg.get("content")
                    if isinstance(content, list) and len(content) > 0:
                        for part in content:
                            if isinstance(part, dict):
                                analisis_text = part.get("text") or part.get("content")
                                if analisis_text:
                                    break
                else:
                    # Fallback a str
                    analisis_text = str(msg)

            # √öltimo recurso: serializar el objeto respuesta
            if not analisis_text:
                try:
                    analisis_text = str(response)
                except Exception:
                    analisis_text = "(no se pudo extraer texto de la respuesta)"

        except Exception as e:
            analisis_text = f"Error extrayendo texto de la respuesta de Gemini: {str(e)}"

        # Limitar tama√±o de la respuesta devuelta al front-end
        if isinstance(analisis_text, str) and len(analisis_text) > 20000:
            analisis_text = analisis_text[:20000] + "\n\n...respuesta truncada..."

        return {
            "success": True,
            "analisis": analisis_text,
            "url": url,
            "_raw_response_debug": None  # campo reservado para debugging en logs (no expuesto en UI)
        }
    
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "analisis": "Error al analizar con Gemini",
            "url": url
        }


def analizar_noticia_completa(url: str, titulo_rss: str = "", descripcion_rss: str = "") -> dict:
    """
    Funci√≥n principal que extrae el contenido de una URL y lo analiza con Gemini.
    Si no puede acceder al contenido, usa el t√≠tulo y descripci√≥n del RSS.
    
    Args:
        url: URL de la noticia
        titulo_rss: T√≠tulo extra√≠do del feed RSS (opcional)
        descripcion_rss: Descripci√≥n extra√≠da del feed RSS (opcional)
    """
    contenido = extraer_contenido_web(url)
    
    # Si hay error de extracci√≥n, usar t√≠tulo y descripci√≥n del RSS
    if contenido.startswith("‚ö†Ô∏è"):
        contexto_adicional = ""
        if titulo_rss or descripcion_rss:
            contexto_adicional = f"\n\nüì∞ INFORMACI√ìN DISPONIBLE DEL RSS:\nT√≠tulo: {titulo_rss}\nDescripci√≥n: {descripcion_rss}\n"
        
        contenido_fallback = f"""‚ö†Ô∏è No se pudo acceder al contenido completo del art√≠culo web.
Motivo: {contenido}
{contexto_adicional}
INSTRUCCIONES: Analiza la noticia bas√°ndote en:
1. La URL (puede indicar el tipo de ataque, v√≠ctima, o grupo)
2. El t√≠tulo y descripci√≥n del RSS si est√°n disponibles
3. Infiere informaci√≥n t√©cnica razonable basada en el contexto

S√© lo m√°s espec√≠fico posible con la informaci√≥n disponible. Si algo no se puede determinar, marca como "No especificado"."""
        
        return analizar_con_gemini(url, contenido_fallback)
    
    resultado = analizar_con_gemini(url, contenido)
    return resultado
